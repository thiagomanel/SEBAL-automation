# Global variables
####################
## private to key run ssh commands
private_key_file=
## federation member to submit tasks
federation_member=

## version of sebal to run
sebal_version=
## tag of sebal to fetch from git repositry
sebal_tag=

# Crawler
## SSH port of crawler VM
#crawler_port=
## port of NFS running in the crawler
#crawler_nfs_port=
## Unix username in crawler
#crawler_user_name=
#crawler_debug_port=
## directory to copy images in remote crawler
#crawler_inputs_dir=
## directory to sabe results in remote crawler
#crawler_outputs_dir=
## version of crawler to run
#crawler_version=
crawler_export_dir=
#crawler_ip=
local_scripts_path=
remote_scripts_path=

ufscar_crawler_user_name=
ufscar_crawler_ip=
ufscar_crawler_port=

lsd_crawler_user_name=
lsd_crawler_ip=
lsd_crawler_port=

#Scheduler
#scheduler_ip=
#scheduler_port=
#scheduler_db_port=
#scheduler_user_name=
#scheduler_debug_port=

#Fetcher
#fetcher_ip=
#fetcher_port=
#fetcher_user_name=
#fetcher_debug_port=

#sebal_db_name=
#sebal_db_user=
#sebal_db_password=
#sebal_db_table_name=

#user_id=
#password=
#auth_url=
#project_id=
#token_type=

#fake_sebal_version=
#fake_sebal_tag=

## string to create pgpass file
pgpass_string="$scheduler_ip:$scheduler_db_port:$sebal_db_name:$sebal_db_user:$sebal_db_password"

## If true, will configure crawler
#is_configure_crawler=true

## public key fetch
#public_key_fetch

## git url
#crawler_sebal_engine_url="https://github.com/fogbow/sebal-engine.git"
## git url
#crawler_manager_url="https://github.com/fogbow/fogbow-manager.git"
## git url
#crawler_blowout_url="https://github.com/fogbow/blowout"

## Tag of the crawler dependecies
#sebal_engine_tag_to_crawler=
#blowout_tag_to_crawler=

#sebal_export_path=/local/exports
fogbow_cli_jar=
manager_ip=
manager_port=
auth_token=
####################
